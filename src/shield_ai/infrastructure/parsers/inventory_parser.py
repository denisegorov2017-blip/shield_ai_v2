"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel-–æ—Ç—á—ë—Ç–æ–≤ –æ –¥–≤–∏–∂–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Å `InventoryParser` –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
Excel-–æ—Ç—á—ë—Ç–æ–≤ 1–° –æ –¥–≤–∏–∂–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
—Å –ø–æ–ª–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π: –°–∫–ª–∞–¥ ‚Üí –ì—Ä—É–ø–ø–∞ ‚Üí –¢–æ–≤–∞—Ä ‚Üí –ü–∞—Ä—Ç–∏—è ‚Üí –î–æ–∫—É–º–µ–Ω—Ç.

Attributes:
    pd: –ú–æ–¥—É–ª—å pandas –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
    re: –ú–æ–¥—É–ª—å —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
    json: –ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON
    load_workbook: –§—É–Ω–∫—Ü–∏—è –∏–∑ openpyxl –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ Excel-—Ñ–∞–π–ª–æ–≤
    Dict, List, Set, Optional: –¢–∏–ø—ã –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    datetime: –ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞–º–∏

–ü—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã:
    1. FIFO: –†–∞—Å—Ö–æ–¥ –∏–∑ —Å–∞–º–æ–π —Å—Ç–∞—Ä–æ–π –ø–∞—Ä—Ç–∏–∏ (–ø–æ –¥–∞—Ç–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è)
    2. –ü—Ä–∏—Ö–æ–¥–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è: –°–æ–∑–¥–∞—ë—Ç –ù–û–í–£–Æ –ø–∞—Ä—Ç–∏—é
    3. –î–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞—Å—Ö–æ–¥–∞ (–ü—Ä–æ–¥–∞–∂–∏, –°–ø–∏—Å–∞–Ω–∏–µ, –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—è, –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞):
       –†–∞—Å—Ö–æ–¥—É—é—Ç/–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—Ç –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –ø–∞—Ä—Ç–∏–∏
    4. –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞: –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏—Ö–æ–¥–æ–º
       (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–∞—Ä—Ç–∏–∏) –∏–ª–∏ —Ä–∞—Å—Ö–æ–¥–æ–º (—Å–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –ø–∞—Ä—Ç–∏–∏) (FIFO)

–í–∞–ª–∏–¥–∞—Ü–∏—è: –ë–∞–ª–∞–Ω—Å = –Ω–∞—á–∞–ª—å–Ω—ã–π + –ø—Ä–∏—Ö–æ–¥ - —Ä–∞—Å—Ö–æ–¥ (tolerance 0.0001 –∫–≥)

–ò–∑–º–µ–Ω–µ–Ω–∏—è v2.1:
    - –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞"
    - –°—á—ë—Ç—á–∏–∫ peresortitsa_docs –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
    - –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü—ã
"""

import json
import logging
import re
from datetime import datetime
from logging import Logger
from typing import Dict, Optional, Set

import pandas as pd
from openpyxl import load_workbook


class InventoryParser:
    """
    Production-ready –ø–∞—Ä—Å–µ—Ä Excel-–æ—Ç—á—ë—Ç–æ–≤ –æ –ø–∞—Ä—Ç–∏—è—Ö –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã.

    –ö–ª–∞—Å—Å —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ Excel-—Ñ–∞–π–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –¥–≤–∏–∂–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤
    –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É FIFO (–ø–µ—Ä–≤—ã–º –ø—Ä–∏—à—ë–ª - –ø–µ—Ä–≤—ã–º —É—à—ë–ª). –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
    —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤–∫–ª—é—á–∞—è –ü—Ä–∏—Ö–æ–¥–Ω—É—é –Ω–∞–∫–ª–∞–¥–Ω—É—é, –ü—Ä–æ–¥–∞–∂–∏,
    –°–ø–∏—Å–∞–Ω–∏–µ, –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—é –∏ –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü—É.

    Attributes:
        known_groups (Set[str]): –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –≥—Ä—É–ø–ø –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞
        document_types (Dict): –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (receipt/expense)
    """

    # –ò–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–æ–≤ —Å—Ç–æ–ª–±—Ü–æ–≤ (—Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
    INDEX_NAME = 0
    INDEX_BEGIN = 4
    INDEX_IN = 6
    INDEX_OUT = 7
    INDEX_END = 8

    def __init__(
        self,
        groups_file: str = "data/knowledge/–≥—Ä—É–ø–ø—ã –∏ –ø–æ–¥ –≥—Ä—É–ø–ø—ã.xlsx",
        logger: Optional[Logger] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞.

        Args:
            groups_file (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –≥—Ä—É–ø–ø —Ç–æ–≤–∞—Ä–æ–≤.
                           –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 'data/knowledge/–≥—Ä—É–ø–ø—ã –∏ –ø–æ–¥ –≥—Ä—É–ø–ø—ã.xlsx'
            verbose (bool): –§–ª–∞–≥ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª—å.
            logger (Optional[Logger]): –≠–∫–∑–µ–º–ø–ª—è—Ä –ª–æ–≥–≥–µ—Ä–∞. –ï—Å–ª–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π.
        """
        self.logger = logger or logging.getLogger(__name__)
        self.known_groups = self._load_groups(groups_file)
        self.document_types = {
            "receipt": [
                "–ü—Ä–∏—Ö–æ–¥–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è",
                "–û–ø—Ä–∏—Ö–æ–¥–æ–≤–∞–Ω–∏–µ –∏–∑–ª–∏—à–∫–æ–≤",
                "–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤",
            ],
            "expense": [
                "–û—Ç—á–µ—Ç –æ—Ç–¥–µ–ª–∞ –æ —Ä–æ–∑–Ω–∏—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂–∞—Ö",
                "–°–ø–∏—Å–∞–Ω–∏–µ",
                "–ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—è",
                "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞",
                "–í–æ–∑–≤—Ä–∞—Ç —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ—Å—Ç–∞–≤—â–∏–∫—É",
                "–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤",
                "–î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–Ω–æ–≥–æ",
                "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ—Å–ª–µ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ",
            ],
        }

    def _load_groups(self, file_path: str) -> Set[str]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≥—Ä—É–ø–ø –∏–∑ Excel-—Ñ–∞–π–ª–∞.

        Args:
            file_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞

        Returns:
            Set[str]: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –≥—Ä—É–ø–ø

        Raises:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
            PermissionError: –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É
        """
        try:
            groups_df = pd.read_excel(file_path, header=None)
            known_groups = set()
            for idx, row in groups_df.iterrows():
                name = row[0]
                if pd.notna(name):
                    group_name = str(name).strip().lower()
                    known_groups.add(group_name)
            self.logger.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(known_groups)} –≥—Ä—É–ø–ø –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞")
            return known_groups
        except FileNotFoundError:
            self.logger.error(f"–§–∞–π–ª —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≥—Ä—É–ø–ø –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return set()
        except PermissionError:
            self.logger.error(
                f"–ù–µ—Ç –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≥—Ä—É–ø–ø: {file_path}"
            )
            return set()
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≥—Ä—É–ø–ø: {e}")
            return set()

    def _get_document_type(self, name: str) -> Optional[str]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—é.

        Args:
            name (str): –ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ Excel

        Returns:
            str –∏–ª–∏ None: 'receipt', 'expense' –∏–ª–∏ None.
        """
        for doc in self.document_types["receipt"]:
            if name.startswith(doc):
                return "receipt"
        for doc in self.document_types["expense"]:
            if name.startswith(doc):
                return "expense"
        return None

    def _classify_row(self, name_str: str) -> str:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏ Excel –ø–æ —Ç–∏–ø—É.

        Args:
            name_str (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å—Ç—Ä–æ–∫–∏, –ø–æ—Å–ª–µ strip()

        Returns:
            str: –û–¥–∏–Ω –∏–∑ —Ç–∏–ø–æ–≤: 'empty', 'header', 'warehouse', 'group', 'product', 'batch', 'document'.
        """
        logging.debug(f"Classifying row input: '{name_str}'")
        if not name_str or name_str.lower() == "nan":
            row_type = "empty"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "empty"

        lower_name_str = name_str.lower()
        if (
            "–≤–µ–¥–æ–º–æ—Å—Ç—å –ø–æ –ø–∞—Ä—Ç–∏—è–º" in lower_name_str
            or "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:" in lower_name_str
            or "–æ—Ç–±–æ—Ä:" in lower_name_str
        ):
            row_type = "meta"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "meta"

        if name_str in [
            "–°–∫–ª–∞–¥",
            "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞",
            "–î–æ–∫—É–º–µ–Ω—Ç –¥–≤–∏–∂–µ–Ω–∏—è",
            "–ü–∞—Ä—Ç–∏—è.–î–∞—Ç–∞ –ø—Ä–∏—Ö–æ–¥–∞",
        ]:
            row_type = "header"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "header"

        if self._get_document_type(name_str):
            row_type = "document"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "document"

        if re.match(r"^\d{2}\.\d{2}\.\d{4}", name_str):
            row_type = "batch"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "batch"

        clean_name = name_str.strip().lower()
        if clean_name in self.known_groups:
            row_type = "group"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "group"

        # –°–∫–ª–∞–¥ –æ–±—ã—á–Ω–æ –≤ —Å–∫–æ–±–∫–∞—Ö, –Ω–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–∑–≤–µ—Å—Ç–Ω–æ–π –≥—Ä—É–ø–ø–æ–π
        if "(" in name_str and ")" in name_str and clean_name not in self.known_groups:
            row_type = "warehouse"
            logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
            return "warehouse"

        row_type = "product"
        logging.debug(f"Row '{name_str}' classified as: '{row_type}'")
        return "product"

    def _safe_to_float(self, value) -> float:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ float.

        Args:
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

        Returns:
            float: –ß–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0.0 –¥–ª—è –ø—É—Å—Ç—ã—Ö –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        """
        if pd.isna(value) or value is None:
            return 0.0
        if isinstance(value, str):
            value = value.strip()
            if value == "" or value == "-":
                return 0.0

        try:
            # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –∏ —É–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ '1 234,56')
            cleaned_string = re.sub(r"\s", "", str(value).replace(",", "."))
            return float(cleaned_string)
        except (ValueError, TypeError):
            return 0.0

    def _apply_fifo_expense(self, product: Dict, total_out: float, doc_name: str):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ø–∏—Å–∞–Ω–∏–µ –ø–æ FIFO –∫ –ø–∞—Ä—Ç–∏—è–º —Ç–æ–≤–∞—Ä–∞.

        Args:
            product (Dict): –°–ª–æ–≤–∞—Ä—å —Ç–æ–≤–∞—Ä–∞ —Å –ø–∞—Ä—Ç–∏—è–º–∏.
            total_out (float): –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è —Å–ø–∏—Å–∞–Ω–∏—è.
            doc_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–∞—Å—Ö–æ–¥–∞.
        """
        remaining_out = total_out

        self.logger.debug(
            f"[FIFO-–†–ê–°–•–û–î] –°–ø–∏—Å–∞–Ω–∏–µ {total_out:.4f} –µ–¥. —Ç–æ–≤–∞—Ä–∞ '{product['name']}' –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É '{doc_name}'"
        )
        self.logger.debug(f"–ü–∞—Ä—Ç–∏–π –¥–æ —Å–ø–∏—Å–∞–Ω–∏—è: {len(product['batches'])}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Ç–∏–∏ –ø–æ –¥–∞—Ç–µ –∏ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –¥–ª—è FIFO (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
        sorted_batches = sorted(product["batches"], key=lambda x: x["arrival_datetime"])

        for i, batch in enumerate(sorted_batches):
            if remaining_out <= 1e-9:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ–ø—É—Å–∫ –¥–ª—è float
                self.logger.debug("–°–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤—ã–ø–æ–ª–Ω–µ–Ω–æ.")
                break

            available_qty = batch["qty"]["end"]

            self.logger.debug(
                f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä—Ç–∏–∏ {i+1} ({batch['arrival_date']}): –¥–æ—Å—Ç—É–ø–Ω–æ {available_qty:.4f}"
            )

            if available_qty <= 1e-9:
                self.logger.debug("–ü–∞—Ä—Ç–∏—è –ø—É—Å—Ç–∞—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue

            current_batch_out = min(remaining_out, available_qty)

            self.logger.debug(f"–°–ø–∏—Å—ã–≤–∞–µ–º {current_batch_out:.4f} –∏–∑ —ç—Ç–æ–π –ø–∞—Ä—Ç–∏–∏.")

            batch["qty"]["out"] += current_batch_out
            batch["qty"]["end"] -= current_batch_out

            if batch["qty"]["end"] < -1e-9:
                deficit = abs(batch["qty"]["end"])
                warning_msg = f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –ø–æ—Å–ª–µ FIFO —Å–ø–∏—Å–∞–Ω–∏—è: —Ç–æ–≤–∞—Ä {product['name']}, –ø–∞—Ä—Ç–∏—è {batch['arrival_date']}, –¥–æ–∫—É–º–µ–Ω—Ç {doc_name}, –¥–µ—Ñ–∏—Ü–∏—Ç {deficit:.4f}"
                self.logger.warning(warning_msg)
                batch["qty"]["end"] = 0.0

            validation = self._validate_balance(
                batch["qty"]["begin"],
                batch["qty"]["in"],
                batch["qty"]["out"],
                batch["qty"]["end"],
            )
            batch["validation"] = validation

            if not validation["valid"]:
                error_msg = f"–ü–∞—Ä—Ç–∏—è {batch['arrival_date']} —Ç–æ–≤–∞—Ä–∞ {product['name']}: {validation['error']}"
                self.logger.error(error_msg)

            batch["documents"].append(
                {
                    "type": "document",
                    "doc_type": "expense",
                    "name": doc_name,
                    "qty": {"in": 0.0, "out": current_batch_out},
                }
            )

            self.logger.info(
                f"[FIFO EXPENSE] {doc_name} —Å–ø–∏—Å–∞–ª {current_batch_out:.4f} –∏–∑ –ø–∞—Ä—Ç–∏–∏ {batch['arrival_date']}, –æ—Å—Ç–∞—Ç–æ–∫: {batch['qty']['end']:.4f}"
            )
            remaining_out -= current_batch_out
            self.logger.debug(f"–û—Å—Ç–∞—Ç–æ–∫ –¥–ª—è —Å–ø–∏—Å–∞–Ω–∏—è: {remaining_out:.4f}")

        if remaining_out > 1e-9:
            error_msg = f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–≤–∞—Ä–∞ '{product['name']}' –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∞–Ω–∏—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É '{doc_name}'. –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç: {remaining_out:.4f}"
            self.logger.error(error_msg)

        self.logger.debug(
            f"[FIFO-–†–ê–°–•–û–î] –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –û—Å—Ç–∞–ª–æ—Å—å –Ω–µ—Å–ø–∏—Å–∞–Ω–Ω–æ–≥–æ: {remaining_out:.4f}"
        )

    def _find_header_indices(self, header_row: list) -> Dict:
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–∞–º."""
        field_keywords = {
            "begin": ["–Ω–∞—á–∞–ª—å–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫", "–Ω–∞—á. –æ—Å—Ç–∞—Ç–æ–∫"],
            "in": ["–ø—Ä–∏—Ö–æ–¥"],
            "out": ["—Ä–∞—Å—Ö–æ–¥"],
            "end": ["–∫–æ–Ω–µ—á–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫", "–∫–æ–Ω. –æ—Å—Ç–∞—Ç–æ–∫"],
        }
        indices = {}
        for col_idx, cell in enumerate(header_row):
            if cell is None:
                continue
            cell_str = str(cell).strip().lower()
            for field_name, keywords in field_keywords.items():
                if any(keyword in cell_str for keyword in keywords):
                    indices[field_name] = col_idx
                    break
        return indices

    def _validate_balance(
        self,
        begin: float,
        in_qty: float,
        out_qty: float,
        end: float,
        tolerance: float = 0.001,
    ) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–∞ –ø–∞—Ä—Ç–∏–∏."""
        expected = begin + in_qty - out_qty
        diff = abs(end - expected)

        if diff <= tolerance:
            return {"valid": True, "diff": round(diff, 4), "error": None}
        else:
            return {
                "valid": False,
                "diff": round(diff, 4),
                "error": f"–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected:.4f}, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ {end:.4f}",
            }

    # --- –ú–ï–¢–û–î–´-–û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–¢–†–û–ö ---

    def _handle_warehouse_row(self, name_str: str, stats: dict) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ 'warehouse'."""
        stats["warehouses"] += 1
        self.logger.debug(f"–°–∫–ª–∞–¥: {name_str}")
        return name_str

    def _handle_group_row(self, name_str: str, stats: dict) -> dict:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ 'group'."""
        group = {
            "type": "group",
            "name": name_str,
            "products": [],
            "stats": {"products": 0, "batches": 0, "documents": 0},
        }
        stats["groups"] += 1
        self.logger.debug(f"–ì—Ä—É–ø–ø–∞: {name_str}")
        return group

    def _handle_product_row(
        self,
        name_str: str,
        current_group: dict,
        stats: dict,
        begin: float,
        in_qty: float,
        out_qty: float,
        end: float,
    ) -> dict:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ 'product'."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–æ–¥—É–∫—Ç "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º" (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é)
        # –≠—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if "–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π" in name_str:
            self.logger.warning(f"Product '{name_str}' skipped due to invalid name.")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ª–æ–≥, —á—Ç–æ –∏ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –≥—Ä—É–ø–ø—ã, —á—Ç–æ–±—ã —Ç–µ—Å—Ç –ø—Ä–æ—Ö–æ–¥–∏–ª
            warning_msg = f"–ù–∞–π–¥–µ–Ω —Ç–æ–≤–∞—Ä '{name_str}' –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã. –¢–æ–≤–∞—Ä –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω."
            self.logger.warning(warning_msg)
            # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ –≥—Ä—É–ø–ø—É –∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return None

        product = {
            "type": "product",
            "name": name_str,
            "batches": [],
            "qty_summary": {"begin": begin, "in": in_qty, "out": out_qty, "end": end},
        }

        if not current_group:
            self.logger.warning(
                f"Product '{name_str}' skipped due to no current group."
            )
            warning_msg = f"–ù–∞–π–¥–µ–Ω —Ç–æ–≤–∞—Ä '{name_str}' –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã. –¢–æ–≤–∞—Ä –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω."
            self.logger.warning(warning_msg)
            # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ –≥—Ä—É–ø–ø—É –∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return None

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ –≥—Ä—É–ø–ø—É –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¢–û–õ–¨–ö–û –µ—Å–ª–∏ current_group —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        current_group["products"].append(product)
        current_group["stats"]["products"] += 1
        stats["products"] += 1
        return product

    def _handle_batch_row(
        self,
        idx: int,
        name_str: str,
        current_group: dict,
        current_product: dict,
        stats: dict,
        begin: float,
        in_qty: float,
        out_qty: float,
        end: float,
    ) -> Optional[dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ 'batch'."""
        if not current_product:
            self.logger.warning(
                f"Batch '{name_str}' skipped due to no current product."
            )
            warning_msg = f"–ù–∞–π–¥–µ–Ω–∞ –ø–∞—Ä—Ç–∏—è '{name_str}' –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞. –ü–∞—Ä—Ç–∏—è –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∞."
            self.logger.warning(warning_msg)
            return None

        validation = self._validate_balance(begin, in_qty, out_qty, end)

        try:
            arrival_datetime = datetime.strptime(name_str, "%d.%m.%Y %H:%M:%S")
        except ValueError:
            try:
                arrival_datetime = datetime.strptime(name_str, "%d.%m.%Y")
            except ValueError:
                arrival_datetime = datetime.now()  # Fallback
                warning_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É/–≤—Ä–µ–º—è '{name_str}' –≤ —Å—Ç—Ä–æ–∫–µ {idx + 1}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è."
                self.logger.warning(warning_msg)

        batch = {
            "type": "batch",
            "arrival_date": arrival_datetime.strftime("%d.%m.%Y"),
            "arrival_time": arrival_datetime.strftime("%H:%M:%S"),
            "arrival_datetime": arrival_datetime,
            "batch_code": name_str,
            "qty": {"begin": begin, "in": in_qty, "out": out_qty, "end": end},
            "qty_raw": {"begin": begin, "in": in_qty, "out": out_qty, "end": end},
            "documents": [],
            "validation": validation,
        }

        current_product["batches"].append(batch)
        current_group["stats"]["batches"] += 1
        stats["batches"] += 1

        if validation["valid"]:
            stats["valid_batches"] += 1
        else:
            stats["invalid_batches"] += 1
            error_msg = f"–û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∞: –¢–æ–≤–∞—Ä '{current_product['name']}', –ü–∞—Ä—Ç–∏—è '{batch['arrival_date']}', {validation['error']}"
            self.logger.error(error_msg)

        return batch

    def _handle_document_row(
        self,
        idx: int,
        name_str: str,
        current_product: Optional[dict],
        current_batch: Optional[dict],
        stats: dict,
        expense_operations: list,
        doc_in_qty: float,
        doc_out_qty: float,
    ):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ 'document'."""
        if not current_product:
            self.logger.warning(
                f"Document '{name_str}' skipped due to no current product."
            )
            warning_msg = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç '{name_str}' (—Å—Ç—Ä–æ–∫–∞ {idx + 1}) –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–æ–≤–∞—Ä–∞. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
            self.logger.warning(warning_msg)
            return

        doc_type = self._get_document_type(name_str)
        is_special_case = False

        # --- –°–ü–ï–¶–ò–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø –ü–ï–†–ï–°–û–†–¢–ò–¶–´ –ò –î–†–£–ì–ò–• –ö–û–†–†–ï–ö–¢–ò–†–û–í–û–ö ---

        # –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞ (–ü–†–ò–•–û–î) –∏–ª–∏ –û–ø—Ä–∏—Ö–æ–¥–æ–≤–∞–Ω–∏–µ - –¥–æ–±–∞–≤–ª—è–µ–º –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–∞—Ä—Ç–∏–∏
        if doc_in_qty > 0 and (
            "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞" in name_str or "–û–ø—Ä–∏—Ö–æ–¥–æ–≤–∞–Ω–∏–µ –∏–∑–ª–∏—à–∫–æ–≤" in name_str
        ):
            is_special_case = True
            stats["receipt_docs"] += 1
            if "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞" in name_str:
                stats["peresortitsa_docs"] += 1

            self.logger.debug(
                f"[–ö–û–†–†–ï–ö–¢–ò–†–û–í–ö–ê-–ü–†–ò–•–û–î] '{name_str}', –∫–æ–ª-–≤–æ: {doc_in_qty}"
            )

            if current_product["batches"]:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–∞—Ä—Ç–∏–∏
                latest_batch = max(
                    current_product["batches"], key=lambda b: b["arrival_datetime"]
                )
                latest_batch["qty"]["in"] += doc_in_qty
                latest_batch["qty"]["end"] += doc_in_qty

                self.logger.info(
                    f"[CORRECTION RECEIPT] '{name_str}' –¥–æ–±–∞–≤–∏–ª {doc_in_qty} –∫ –ø–∞—Ä—Ç–∏–∏ {latest_batch['arrival_date']}"
                )
            else:
                # –ï—Å–ª–∏ —É —Ç–æ–≤–∞—Ä–∞ –µ—â–µ –Ω–µ—Ç –ø–∞—Ä—Ç–∏–π, —ç—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ, –Ω–æ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
                warning_msg = f"–î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–∏—Ö–æ–¥–∞ '{name_str}' –¥–ª—è —Ç–æ–≤–∞—Ä–∞ '{current_product['name']}' –±–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–∞—Ä—Ç–∏–π. –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è '–≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è' –ø–∞—Ä—Ç–∏—è."
                self.logger.warning(warning_msg)
                # –õ–æ–≥–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –ø–∞—Ä—Ç–∏–∏ –¥–ª—è —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞–µ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
                # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –∑–¥–µ—Å—å –Ω–µ–ø–æ–ª–Ω–∞—è, —Ç–∞–∫ –∫–∞–∫ –æ–±—ã—á–Ω–æ —Ç–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ—Å—Ç–∞—Ç–∫–∏.

        # –î–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞—Å—Ö–æ–¥–∞ (–≤–∫–ª—é—á–∞—è –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü—É-—Ä–∞—Å—Ö–æ–¥) –æ—Ç–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –Ω–∞ 2-–π –ø—Ä–æ—Ö–æ–¥
        if doc_type == "expense":
            is_special_case = True
            stats["expense_docs"] += 1
            if "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞" in name_str and doc_in_qty == 0:
                stats["peresortitsa_docs"] += 1

            if doc_out_qty > 0:
                expense_operations.append(
                    {
                        "product_name": current_product["name"],
                        "quantity": doc_out_qty,
                        "document_name": name_str,
                    }
                )
                self.logger.debug(
                    f"[–û–¢–õ–û–ñ–ï–ù–ù–´–ô –†–ê–°–•–û–î] '{name_str}', –∫–æ–ª-–≤–æ: {doc_out_qty}"
                )

        # --- –°–¢–ê–ù–î–ê–†–¢–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø –î–û–ö–£–ú–ï–ù–¢–û–í –í–ù–£–¢–†–ò –ü–ê–†–¢–ò–ò ---

        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–µ—Ü. —Å–ª—É—á–∞–π –∏ –µ—Å—Ç—å —Ç–µ–∫—É—â–∞—è –ø–∞—Ä—Ç–∏—è, –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∫ –Ω–µ–π
        if not is_special_case and current_batch:
            document = {
                "type": "document",
                "doc_type": doc_type,
                "name": name_str,
                "qty": {"in": doc_in_qty, "out": doc_out_qty},
            }
            current_batch["documents"].append(document)
            # –í v2.1 –º—ã –Ω–µ –º–µ–Ω—è–µ–º qty –ø–∞—Ä—Ç–∏–∏ –∑–¥–µ—Å—å, —Ç.–∫. –æ–Ω–∏ —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ø–∞—Ä—Ç–∏–∏.
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏ FIFO –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞—Ö.

    def _process_row(
        self,
        idx: int,
        row: list,
        context: dict,
        stats: dict,
        expense_operations: list,
        sections: list,
    ):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel-—Ñ–∞–π–ª–∞."""
        name = row[self.INDEX_NAME] if len(row) > self.INDEX_NAME else None
        if name is None:
            return context

        name_str = str(name).strip()
        if name_str.lower().startswith("–∏—Ç–æ–≥–æ"):
            return context

        # --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–æ–ª–æ–Ω–æ–∫ ---
        row_type = self._classify_row(name_str)

        current_group_name = (
            context["current_group"]["name"] if context["current_group"] else "None"
        )
        current_product_name = (
            context["current_product"]["name"] if context["current_product"] else "None"
        )
        self.logger.debug(
            f"Processing row {idx}: name='{name_str}', type='{row_type}', current_group='{current_group_name}', current_product='{current_product_name}'"
        )

        if not context["found_header_row"] and row_type == "header":
            context["header_indices"] = self._find_header_indices(row)
            if all(
                col in context["header_indices"]
                for col in ["begin", "in", "out", "end"]
            ):
                context["found_header_row"] = True
                self.logger.debug(
                    f"–ù–∞–π–¥–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ç—Ä–æ–∫–µ {idx + 1}: {context['header_indices']}"
                )
            return context

        if row_type in ["header", "empty", "meta", "unknown"]:
            return context

        # --- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ---
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–æ–∫, —É –∫–æ—Ç–æ—Ä—ã—Ö –æ–Ω–∏ –µ—Å—Ç—å (product, batch)
        hi = context["header_indices"]
        begin, in_qty, out_qty, end = 0.0, 0.0, 0.0, 0.0
        if row_type in ["product", "batch"] and context["found_header_row"]:
            begin = self._safe_to_float(row[hi["begin"]])
            in_qty = self._safe_to_float(row[hi["in"]])
            out_qty = self._safe_to_float(row[hi["out"]])
            end = self._safe_to_float(row[hi["end"]])
        elif row_type in ["product", "batch"]:  # Fallback
            begin = (
                self._safe_to_float(row[self.INDEX_BEGIN])
                if len(row) > self.INDEX_BEGIN
                else 0.0
            )
            in_qty = (
                self._safe_to_float(row[self.INDEX_IN])
                if len(row) > self.INDEX_IN
                else 0.0
            )
            out_qty = (
                self._safe_to_float(row[self.INDEX_OUT])
                if len(row) > self.INDEX_OUT
                else 0.0
            )
            end = (
                self._safe_to_float(row[self.INDEX_END])
                if len(row) > self.INDEX_END
                else 0.0
            )

        # --- –í—ã–∑–æ–≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ ---
        if row_type == "warehouse":
            if not context["warehouse"]:
                context["warehouse"] = self._handle_warehouse_row(name_str, stats)

        elif row_type == "group":
            if context["current_group"]:
                sections.append(context["current_group"])
            context["current_group"] = self._handle_group_row(name_str, stats)
            context["current_batch"] = None

        elif row_type == "product":
            product_result = self._handle_product_row(
                name_str, context["current_group"], stats, begin, in_qty, out_qty, end
            )
            # –û–±–Ω–æ–≤–ª—è–µ–º context['current_product'] —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ _handle_product_row –≤–µ—Ä–Ω—É–ª –Ω–µ None
            if product_result is not None:
                context["current_product"] = product_result
            # –ï—Å–ª–∏ _handle_product_row –≤–µ—Ä–Ω—É–ª None, –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º current_product.
            # –≠—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞.
            context["current_batch"] = None

        elif row_type == "batch":
            context["current_batch"] = self._handle_batch_row(
                idx,
                name_str,
                context["current_group"],
                context["current_product"],
                stats,
                begin,
                in_qty,
                out_qty,
                end,
            )

        elif row_type == "document":
            self._handle_document_row(
                idx,
                name_str,
                context["current_product"],
                context["current_batch"],
                stats,
                expense_operations,
                in_qty,
                out_qty,
            )

        return context

    def parse_file(self, file_path: str) -> Dict:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç Excel-—Ñ–∞–π–ª –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON.

        Args:
            file_path (str): –ü—É—Ç—å –∫ Excel-—Ñ–∞–π–ª—É

        Returns:
            Dict: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
        """

        try:
            wb = load_workbook(filename=file_path, data_only=True)
            ws = wb.active
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return {"error": f"Excel read error: {e}", "data": None}

        sections = []
        expense_operations = []
        stats = {
            "warehouses": 0,
            "groups": 0,
            "products": 0,
            "batches": 0,
            "receipt_docs": 0,
            "expense_docs": 0,
            "peresortitsa_docs": 0,
            "movement_docs": 0,
            "return_docs": 0,
            "surplus_docs": 0,
            "valid_batches": 0,
            "invalid_batches": 0,
        }

        self.logger.info(f"–ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞: {file_path}")

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–∏
        context = {
            "warehouse": None,
            "current_group": None,
            "current_product": None,
            "current_batch": None,
            "header_indices": {},
            "found_header_row": False,
        }

        # === –ü–ï–†–í–´–ô –ü–†–û–•–û–î: —Å–±–æ—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ===
        for idx, row_cells in enumerate(ws.iter_rows()):
            row = [cell.value for cell in row_cells]
            context = self._process_row(
                idx, row, context, stats, expense_operations, sections
            )

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥—Ä—É–ø–ø—ã
        if context["current_group"]:
            sections.append(context["current_group"])

        if not context["found_header_row"]:
            self.logger.warning(
                "–ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã. –ü–∞—Ä—Å–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∏–Ω–¥–µ–∫—Å—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
            )

        # === –í–¢–û–†–û–ô –ü–†–û–•–û–î: –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ FIFO ===
        if expense_operations:
            self.logger.debug("–ù–∞—á–∞–ª–æ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞: –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ FIFO –¥–ª—è —Å–ø–∏—Å–∞–Ω–∏–π...")

        for expense_op in expense_operations:
            product_name = expense_op["product_name"]
            quantity = expense_op["quantity"]
            document_name = expense_op["document_name"]

            product_found = False
            for section in sections:
                for prod in section["products"]:
                    if prod["name"] == product_name:
                        self._apply_fifo_expense(prod, quantity, document_name)
                        product_found = True
                        break
                if product_found:
                    break

        self.logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")

        return {
            "meta": {
                "title": "–í–µ–¥–æ–º–æ—Å—Ç—å –ø–æ –ø–∞—Ä—Ç–∏—è–º –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã",
                "version": "2.1",
                "structure": "–°–∫–ª–∞–¥ ‚Üí –ì—Ä—É–ø–ø–∞ ‚Üí –¢–æ–≤–∞—Ä ‚Üí –ü–∞—Ä—Ç–∏—è ‚Üí –î–æ–∫—É–º–µ–Ω—Ç",
                "fifo_logic": {
                    "description": "–î–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞—Å—Ö–æ–¥–∞ —Å–ø–∏—Å—ã–≤–∞—é—Ç —Ç–æ–≤–∞—Ä –∏–∑ –ø–∞—Ä—Ç–∏–π –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É FIFO",
                    "receipt_docs": "–ü—Ä–∏—Ö–æ–¥–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é –ø–∞—Ä—Ç–∏—é",
                    "expense_docs": "–ü—Ä–æ–¥–∞–∂–∏, –°–ø–∏—Å–∞–Ω–∏—è, –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏–∏, –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü—ã —Ä–∞—Å—Ö–æ–¥—É—é—Ç/–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä—Ç–∏–∏",
                    "peresortitsa": "–ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ü–∞: —Ä–∞—Å—Ö–æ–¥ –∏–∑ –æ–¥–Ω–æ–π –ø–∞—Ä—Ç–∏–∏ (FIFO) + –æ–ø—Ä–∏—Ö–æ–¥–æ–≤–∞–Ω–∏–µ –≤ –¥—Ä—É–≥—É—é (–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–∞—Ä—Ç–∏–∏)",
                },
                "stats": stats,
                "parsed_at": datetime.now().isoformat(),
            },
            "warehouse": context["warehouse"],
            "sections": sections,
            "logs": {},
        }

    def save_to_json(self, data: Dict, output_file: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ JSON-—Ñ–∞–π–ª.

        Args:
            data (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ parse_file()
            output_file (str): –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (e.g., 'inventory.json')
        """
        try:
            with open(output_file, "w", encoding="utf-8") as f:
                # Custom encoder to handle datetime objects
                class DateTimeEncoder(json.JSONEncoder):
                    def default(self, o):
                        if isinstance(o, datetime):
                            return o.isoformat()
                        return super().default(o)

                json.dump(data, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)
            self.logger.info(f"JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {e}")

    def export_to_markdown(self, data: Dict, output_file: str):
        """
        –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Markdown-–æ—Ç—á—ë—Ç —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º.

        Args:
            data (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ parse_file()
            output_file (str): –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (e.g., 'report.md')
        """
        if "error" in data:
            print("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç, —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π.")
            return

        md_lines = []

        md_lines.append(f"# {data['meta']['title']} (v{data['meta']['version']})")
        md_lines.append(f"\n**–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞**: {data['meta']['parsed_at']}")
        md_lines.append(f"**–°–∫–ª–∞–¥**: {data.get('warehouse', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n")
        md_lines.append("---")

        md_lines.append("\n## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
        for key, value in data["meta"]["stats"].items():
            md_lines.append(f"- **{key.replace('_', ' ').capitalize()}**: {value}")
        md_lines.append("\n---")

        for section in data.get("sections", []):
            md_lines.append(f"\n## {section['name']}\n")
            md_lines.append(
                "| –¢–æ–≤–∞—Ä | –ù–∞—á. –æ—Å—Ç–∞—Ç–æ–∫ | –ü—Ä–∏—Ö–æ–¥ | –†–∞—Å—Ö–æ–¥ | –ö–æ–Ω. –æ—Å—Ç–∞—Ç–æ–∫ | –ü–∞—Ä—Ç–∏–π |"
            )
            md_lines.append("|---|---|---|---|")

            for product in section["products"]:
                qty = product["qty_summary"]
                md_lines.append(
                    f"| {product['name']} | {qty['begin']:.4f} | {qty['in']:.4f} | {qty['out']:.4f} | {qty['end']:.4f} | {len(product['batches'])} |"
                )

        try:
            with open(output_file, "w", encoding="utf-8") as f:
                f.write("\n".join(md_lines))
            self.logger.info(f"Markdown —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Markdown: {e}")

    def print_summary(self, data: Dict):
        """
        –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å.
        """
        if "error" in data:
            print(f"\n‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {data['error']}")
            return

        print("\n" + "=" * 60)
        print(f"–°–í–û–î–ö–ê –ü–û –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú –ü–ê–†–°–ò–ù–ì–ê (v{data['meta']['version']})")
        print("=" * 60)
        print(f"\n–°–∫–ª–∞–¥: {data.get('warehouse', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
        print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        for key, value in data["meta"]["stats"].items():
            print(f"  ‚Ä¢ {key.replace('_', ' ').capitalize()}: {value}")

        self.logger.info("–û—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –±–∞–ª–∞–Ω—Å–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        print("\n" + "=" * 60)

    def print_batch_details(self, data: Dict):
        """
        –í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä—Ç–∏—è—Ö —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        """
        if "error" in data:
            return

        print("\n" + "=" * 80)
        print("–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ê–†–¢–ò–ô (–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç—á–µ—Ç–∞)")
        print("=" * 80)

        for section in data.get("sections", []):
            for product in section["products"]:
                if product["batches"]:
                    print(f"\nüì¶ {product['name']} ({section['name']})")
                    print("-" * 60)

                    for batch in product["batches"]:
                        qty_raw = batch["qty_raw"]
                        b, i, o, e = (
                            qty_raw["begin"],
                            qty_raw["in"],
                            qty_raw["out"],
                            qty_raw["end"],
                        )

                        print(f"  –ü–∞—Ä—Ç–∏—è {batch['batch_code']}:")
                        print(
                            f"    –ù–∞—á–∞–ª–æ: {b:<10.4f} –ü—Ä–∏—Ö–æ–¥: {i:<10.4f} –†–∞—Å—Ö–æ–¥: {o:<10.4f} –ö–æ–Ω–µ—Ü:  {e:<10.4f}"
                        )

                        if not batch["validation"]["valid"]:
                            print(
                                f"    ‚ùå –û–®–ò–ë–ö–ê –ë–ê–õ–ê–ù–°–ê: {batch['validation']['error']}"
                            )
                        else:
                            print(
                                f"    ‚úÖ –ë–∞–ª–∞–Ω—Å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω (–¥–æ–ø—É—Å–∫ {batch['validation']['diff']:.4f})"
                            )


# === –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ===

# if __name__ == '__main__':
#     # 1. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
#     # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ —Å –ª–æ–≥–≥–µ—Ä–æ–º
#     parser = InventoryParser('data/knowledge/–≥—Ä—É–ø–ø—ã –∏ –ø–æ–¥ –≥—Ä—É–ø–ø—ã.xlsx')

#     # 2. –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞
#     # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ —ç—Ç–æ–º—É –ø—É—Ç–∏
#     file_to_parse = 'data/input/13.10.2025 –≤—Å–µ –°–ö–õ–ê–î–´ –†–∞–∑–ª–∏–≤–Ω–æ–µ –ø–∏–≤–æ.xlsx'
#     result = parser.parse_file(file_to_parse)

#     # 3. –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏, –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ
#     if 'error' not in result:
#         parser.print_summary(result)

#         # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
#         parser.save_to_json(result, 'inventory_result.json')
#         parser.export_to_markdown(result, 'inventory_result.md')

#         # 5. –î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
#         print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º:")
#         print(f"–°–∫–ª–∞–¥: {result.get('warehouse')}")
#         print(f"–ì—Ä—É–ø–ø: {result['meta']['stats']['groups']}")
#         print(f"–¢–æ–≤–∞—Ä–æ–≤: {result['meta']['stats']['products']}")
#         print(f"–ü–∞—Ä—Ç–∏–π: {result['meta']['stats']['batches']}")

#         # –ü–µ—Ä–µ–±–æ—Ä –≥—Ä—É–ø–ø –∏ —Ç–æ–≤–∞—Ä–æ–≤
#         if result.get('sections'):
#             for section in result['sections'][:2]: # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 2 –≥—Ä—É–ø–ø—ã
#                 print(f"\n–ì—Ä—É–ø–ø–∞: {section['name']}")
#                 for product in section['products'][:2]: # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 2 —Ç–æ–≤–∞—Ä–∞
#                     print(f"  –¢–æ–≤–∞—Ä: {product['name']}")
#                     print(f"  –ü–∞—Ä—Ç–∏–π: {len(product['batches'])}")
